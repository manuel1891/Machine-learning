{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# This is needed to make xgboost run\n",
    "import os\n",
    "mingw_path = 'C:\\\\Program Files\\\\mingw-w64\\\\x86_64-6.2.0-posix-seh-rt_v5-rev1\\\\mingw64\\\\bin'\n",
    "os.environ['PATH'] = mingw_path + ';' + os.environ['PATH']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import csv\n",
    "import datetime\n",
    "import random\n",
    "from operator import sub\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xgboost as xgb \n",
    "from sklearn import preprocessing, ensemble\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Doing manual preprocessing: changing all strings to integers in order to make digestable inputs for machine learning algorithms\n",
    "mapping_dict = {\n",
    "'ind_empleado'  : {-99:0, 'N':1, 'B':2, 'F':3, 'A':4, 'S':5},\n",
    "'sexo'          : {'V':0, 'H':1, -99:2},\n",
    "'ind_nuevo'     : {'0':0, '1':1, -99:2},\n",
    "'indrel'        : {'1':0, '99':1, -99:2},\n",
    "'indrel_1mes'   : {-99:0, '1.0':1, '1':1, '2.0':2, '2':2, '3.0':3, '3':3, '4.0':4, '4':4, 'P':5},\n",
    "'tiprel_1mes'   : {-99:0, 'I':1, 'A':2, 'P':3, 'R':4, 'N':5},\n",
    "'indresi'       : {-99:0, 'S':1, 'N':2},\n",
    "'indext'        : {-99:0, 'S':1, 'N':2},\n",
    "#'conyuemp'      : {-99:0, 'S':1, 'N':2},\n",
    "'indfall'       : {-99:0, 'S':1, 'N':2},\n",
    "#'tipodom'       : {-99:0, '1':1},\n",
    "'ind_actividad_cliente' : {'0':0, '1':1, -99:2},\n",
    "'segmento'      : {'02 - PARTICULARES':0, '03 - UNIVERSITARIO':1, '01 - TOP':2, -99:2},\n",
    "'pais_residencia' : {'LV': 102, 'BE': 12, 'BG': 50, 'BA': 61, 'BM': 117, 'BO': 62, 'JP': 82, 'JM': 116, 'BR': 17, 'BY': 64, 'BZ': 113, 'RU': 43, 'RS': 89, 'RO': 41, 'GW': 99, 'GT': 44, 'GR': 39, 'GQ': 73, 'GE': 78, 'GB': 9, 'GA': 45, 'GN': 98, 'GM': 110, 'GI': 96, 'GH': 88, 'OM': 100, 'HR': 67, 'HU': 106, 'HK': 34, 'HN': 22, 'AD': 35, 'PR': 40, 'PT': 26, 'PY': 51, 'PA': 60, 'PE': 20, 'PK': 84, 'PH': 91, 'PL': 30, 'EE': 52, 'EG': 74, 'ZA': 75, 'EC': 19, 'AL': 25, 'VN': 90, 'ET': 54, 'ZW': 114, 'ES': 0, 'MD': 68, 'UY': 77, 'MM': 94, 'ML': 104, 'US': 15, 'MT': 118, 'MR': 48, 'UA': 49, 'MX': 16, 'IL': 42, 'FR': 8, 'MA': 38, 'FI': 23, 'NI': 33, 'NL': 7, 'NO': 46, 'NG': 83, 'NZ': 93, 'CI': 57, 'CH': 3, 'CO': 21, 'CN': 28, 'CM': 55, 'CL': 4, 'CA': 2, 'CG': 101, 'CF': 109, 'CD': 112, 'CZ': 36, 'CR': 32, 'CU': 72, 'KE': 65, 'KH': 95, 'SV': 53, 'SK': 69, 'KR': 87, 'KW': 92, 'SN': 47, 'SL': 97, 'KZ': 111, 'SA': 56, 'SG': 66, 'SE': 24, 'DO': 11, 'DJ': 115, 'DK': 76, 'DE': 10, 'DZ': 80, 'MK': 105, -99: 1, 'LB': 81, 'TW': 29, 'TR': 70, 'TN': 85, 'LT': 103, 'LU': 59, 'TH': 79, 'TG': 86, 'LY': 108, 'AE': 37, 'VE': 14, 'IS': 107, 'IT': 18, 'AO': 71, 'AR': 13, 'AU': 63, 'AT': 6, 'IN': 31, 'IE': 5, 'QA': 58, 'MZ': 27},\n",
    "'canal_entrada' : {'013': 49, 'KHP': 160, 'KHQ': 157, 'KHR': 161, 'KHS': 162, 'KHK': 10, 'KHL': 0, 'KHM': 12, 'KHN': 21, 'KHO': 13, 'KHA': 22, 'KHC': 9, 'KHD': 2, 'KHE': 1, 'KHF': 19, '025': 159, 'KAC': 57, 'KAB': 28, 'KAA': 39, 'KAG': 26, 'KAF': 23, 'KAE': 30, 'KAD': 16, 'KAK': 51, 'KAJ': 41, 'KAI': 35, 'KAH': 31, 'KAO': 94, 'KAN': 110, 'KAM': 107, 'KAL': 74, 'KAS': 70, 'KAR': 32, 'KAQ': 37, 'KAP': 46, 'KAW': 76, 'KAV': 139, 'KAU': 142, 'KAT': 5, 'KAZ': 7, 'KAY': 54, 'KBJ': 133, 'KBH': 90, 'KBN': 122, 'KBO': 64, 'KBL': 88, 'KBM': 135, 'KBB': 131, 'KBF': 102, 'KBG': 17, 'KBD': 109, 'KBE': 119, 'KBZ': 67, 'KBX': 116, 'KBY': 111, 'KBR': 101, 'KBS': 118, 'KBP': 121, 'KBQ': 62, 'KBV': 100, 'KBW': 114, 'KBU': 55, 'KCE': 86, 'KCD': 85, 'KCG': 59, 'KCF': 105, 'KCA': 73, 'KCC': 29, 'KCB': 78, 'KCM': 82, 'KCL': 53, 'KCO': 104, 'KCN': 81, 'KCI': 65, 'KCH': 84, 'KCK': 52, 'KCJ': 156, 'KCU': 115, 'KCT': 112, 'KCV': 106, 'KCQ': 154, 'KCP': 129, 'KCS': 77, 'KCR': 153, 'KCX': 120, 'RED': 8, 'KDL': 158, 'KDM': 130, 'KDN': 151, 'KDO': 60, 'KDH': 14, 'KDI': 150, 'KDD': 113, 'KDE': 47, 'KDF': 127, 'KDG': 126, 'KDA': 63, 'KDB': 117, 'KDC': 75, 'KDX': 69, 'KDY': 61, 'KDZ': 99, 'KDT': 58, 'KDU': 79, 'KDV': 91, 'KDW': 132, 'KDP': 103, 'KDQ': 80, 'KDR': 56, 'KDS': 124, 'K00': 50, 'KEO': 96, 'KEN': 137, 'KEM': 155, 'KEL': 125, 'KEK': 145, 'KEJ': 95, 'KEI': 97, 'KEH': 15, 'KEG': 136, 'KEF': 128, 'KEE': 152, 'KED': 143, 'KEC': 66, 'KEB': 123, 'KEA': 89, 'KEZ': 108, 'KEY': 93, 'KEW': 98, 'KEV': 87, 'KEU': 72, 'KES': 68, 'KEQ': 138, -99: 6, 'KFV': 48, 'KFT': 92, 'KFU': 36, 'KFR': 144, 'KFS': 38, 'KFP': 40, 'KFF': 45, 'KFG': 27, 'KFD': 25, 'KFE': 148, 'KFB': 146, 'KFC': 4, 'KFA': 3, 'KFN': 42, 'KFL': 34, 'KFM': 141, 'KFJ': 33, 'KFK': 20, 'KFH': 140, 'KFI': 134, '007': 71, '004': 83, 'KGU': 149, 'KGW': 147, 'KGV': 43, 'KGY': 44, 'KGX': 24, 'KGC': 18, 'KGN': 11}\n",
    "}\n",
    "cat_cols = list(mapping_dict.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "target_cols = ['ind_ahor_fin_ult1','ind_aval_fin_ult1','ind_cco_fin_ult1','ind_cder_fin_ult1','ind_cno_fin_ult1','ind_ctju_fin_ult1','ind_ctma_fin_ult1','ind_ctop_fin_ult1','ind_ctpp_fin_ult1','ind_deco_fin_ult1','ind_deme_fin_ult1','ind_dela_fin_ult1','ind_ecue_fin_ult1','ind_fond_fin_ult1','ind_hip_fin_ult1','ind_plan_fin_ult1','ind_pres_fin_ult1','ind_reca_fin_ult1','ind_tjcr_fin_ult1','ind_valo_fin_ult1','ind_viv_fin_ult1','ind_nomina_ult1','ind_nom_pens_ult1','ind_recibo_ult1']\n",
    "\n",
    "# Deletes the first two products, as noone buys them\n",
    "target_cols = target_cols[2:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def SumProd(row):\n",
    "    plist = []\n",
    "    for col in target_cols:\n",
    "        if row[col].strip() in ['', 'NA']:\n",
    "            target = 0\n",
    "        else:\n",
    "            target = int(float(row[col]))\n",
    "        plist.append(target)\n",
    "        total = sum(plist[i] for i in plist if i == 1)\n",
    "    return total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def getTarget(row):\n",
    "    tlist = []\n",
    "    for col in target_cols:\n",
    "        if row[col].strip() in ['', 'NA']:\n",
    "            target = 0\n",
    "        else:\n",
    "            target = int(float(row[col]))\n",
    "        tlist.append(target)\n",
    "    return tlist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def getIndex(row, col):\n",
    "    val = row[col].strip()\n",
    "    if val not in ['','NA']:\n",
    "        ind = mapping_dict[col][val]\n",
    "    else:\n",
    "        ind = mapping_dict[col][-99]\n",
    "    return ind\n",
    "#changes the values in the data set to a normalised amount (replacing strings by int, looping through the col and rows) \n",
    "# according to the mapping_dict provided "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Does the same as the getIndex function, but also imputes Null, minimum and maximum values.\n",
    "def getAge(row):\n",
    "    mean_age = 40.\n",
    "    min_age = 18.\n",
    "    max_age = 100.\n",
    "    range_age = max_age - min_age\n",
    "    age = row['age'].strip()\n",
    "    if age == 'NA' or age == '':\n",
    "        age = mean_age\n",
    "    else:\n",
    "        age = float(age)\n",
    "        if age < min_age:\n",
    "            age = min_age\n",
    "        elif age > max_age:\n",
    "            age = max_age\n",
    "    return round( (age - min_age) / range_age, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Normalise seniorities and set values=0 for nulls\n",
    "def getCustSeniority(row):\n",
    "    min_value = 0.\n",
    "    max_value = 256.\n",
    "    range_value = max_value - min_value\n",
    "    missing_value = 0.\n",
    "    cust_seniority = row['antiguedad'].strip()\n",
    "    if cust_seniority == 'NA' or cust_seniority == '':\n",
    "        cust_seniority = missing_value\n",
    "    else:\n",
    "        cust_seniority = float(cust_seniority)\n",
    "        if cust_seniority < min_value:\n",
    "            cust_seniority = min_value\n",
    "        elif cust_seniority > max_value:\n",
    "            cust_seniority = max_value\n",
    "    return round((cust_seniority-min_value) / range_value, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Imputes Renta null values using averages for province, otherwise uses an average if both are null.  \n",
    "def getRent(row):\n",
    "    min_value = 0.\n",
    "    max_value = 1500000.\n",
    "    range_value = max_value - min_value\n",
    "    renta_dict = {'ALBACETE': 76895,  'ALICANTE': 60562,  'ALMERIA': 77815,  'ASTURIAS': 83995,  'AVILA': 78525,  'BADAJOZ': 60155,  'BALEARS, ILLES': 114223,  'BARCELONA': 135149,  'BURGOS': 87410, 'NAVARRA' : 101850,\n",
    "    'CACERES': 78691,  'CADIZ': 75397,  'CANTABRIA': 87142,  'CASTELLON': 70359,  'CEUTA': 333283, 'CIUDAD REAL': 61962,  'CORDOBA': 63260,  'CORUÃ‘A, A': 103567,  'CUENCA': 70751,  'GIRONA': 100208,  'GRANADA': 80489,\n",
    "    'GUADALAJARA': 100635,  'HUELVA': 75534,  'HUESCA': 80324,  'JAEN': 67016,  'LEON': 76339,  'LERIDA': 59191,  'LUGO': 68219,  'MADRID': 141381,  'MALAGA': 89534,  'MELILLA': 116469, 'GIPUZKOA': 101850,\n",
    "    'MURCIA': 68713,  'OURENSE': 78776,  'PALENCIA': 90843,  'PALMAS, LAS': 78168,  'PONTEVEDRA': 94328,  'RIOJA, LA': 91545,  'SALAMANCA': 88738,  'SANTA CRUZ DE TENERIFE': 83383, 'ALAVA': 101850, 'BIZKAIA' : 101850,\n",
    "    'SEGOVIA': 81287,  'SEVILLA': 94814,  'SORIA': 71615,  'TARRAGONA': 81330,  'TERUEL': 64053,  'TOLEDO': 65242,  'UNKNOWN': 103689,  'VALENCIA': 73463,  'VALLADOLID': 92032,  'ZAMORA': 73727,  'ZARAGOZA': 98827}\n",
    "\n",
    "    #missing_value = 101850.\n",
    "    rent = row['renta'].strip()\n",
    "    if rent == 'NA' or rent == '':\n",
    "        if row['nomprov'] == 'NA' or row['nomprov'] == '':\n",
    "            rent = float(renta_dict['UNKNOWN'])\n",
    "        else:\n",
    "            rent = float(renta_dict[row['nomprov']])\n",
    "    else:\n",
    "        rent = float(rent)\n",
    "        if rent < min_value:\n",
    "            rent = min_value\n",
    "        elif rent > max_value:\n",
    "            rent = max_value\n",
    "\n",
    "    return round((rent-min_value) / range_value, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def getMarriageIndex(row, age, sex, income):\n",
    "    marriage_age = 28\n",
    "    modifier = 0\n",
    "    if sex == 'V':\n",
    "        modifier += -2\n",
    "    if income <= 101850:\n",
    "        modifier += -1\n",
    "    \n",
    "    marriage_age_mod = marriage_age + modifier\n",
    "    \n",
    "    if age <= marriage_age_mod:\n",
    "        return 0\n",
    "    else:\n",
    "        return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def getMonth(row):\n",
    "    return int(row['fecha_dato'].split('-')[1])\n",
    "\n",
    "def getjoinMonth(row):\n",
    "    if row['fecha_alta'].strip() == 'NA' or row['fecha_alta'].strip() == '':\n",
    "        return int(random.choice([1,2,3,4,5,6,7,8,9,10,11,12]))\n",
    "    else:\n",
    "        return int(row['fecha_alta'].split('-')[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def processDataMK(in_file_name, cust_dict, lag_cust_dict, lag1_cust_dict, lag2_cust_dict, lag3_cust_dict, lag4_cust_dict, lag5_cust_dict):\n",
    "    x_vars_list = []\n",
    "    y_vars_list = []\n",
    "    \n",
    "    for row in csv.DictReader(in_file_name):\n",
    "        if row['fecha_dato'] not in ['2015-11-28','2015-12-28','2015-04-28', '2015-05-28', '2015-06-28', '2016-04-28', '2016-05-28', '2016-06-28', '2016-01-28','2016-02-28', '2015-01-28', '2015-02-28', '2015-03-28','2016-03-28']:\n",
    "            continue\n",
    "        #Leave out first month\n",
    "        cust_id = int(row['ncodpers'])\n",
    "        \n",
    "        if (row['fecha_dato'] in ['2015-11-28'] ):\n",
    "            target_list = getTarget(row)\n",
    "            lag5_cust_dict[cust_id] =  target_list[:]\n",
    "            continue\n",
    "        \n",
    "        if (row['fecha_dato'] in ['2015-12-28'] ):\n",
    "            target_list = getTarget(row)\n",
    "            lag4_cust_dict[cust_id] =  target_list[:]\n",
    "            continue\n",
    "        \n",
    "        if (row['fecha_dato'] in ['2015-01-28', '2016-01-28'] ):\n",
    "            target_list = getTarget(row)\n",
    "            lag3_cust_dict[cust_id] =  target_list[:]\n",
    "            continue\n",
    "            \n",
    "        if (row['fecha_dato'] in ['2015-02-28', '2016-02-28'] ):\n",
    "            target_list = getTarget(row)\n",
    "            lag2_cust_dict[cust_id] =  target_list[:]\n",
    "            continue\n",
    "        \n",
    "        if (row['fecha_dato'] in ['2015-03-28', '2016-03-28'] ):\n",
    "            target_list = getTarget(row)\n",
    "            lag1_cust_dict[cust_id] =  target_list[:]\n",
    "            continue\n",
    "            \n",
    "        if (row['fecha_dato'] in ['2015-04-28', '2016-04-28'] ):\n",
    "            target_list = getTarget(row)\n",
    "            lag_cust_dict[cust_id] =  target_list[:]\n",
    "            continue\n",
    "        \n",
    "        if (row['fecha_dato'] in ['2015-05-28', '2016-05-28'] ):\n",
    "            target_list = getTarget(row)\n",
    "            cust_dict[cust_id] =  target_list[:]\n",
    "            continue\n",
    "        \n",
    "        x_vars = []\n",
    "            \n",
    "        for col in cat_cols:\n",
    "            x_vars.append( getIndex(row, col) )\n",
    "        sex = getIndex(row, 'sexo')\n",
    "        age = getAge(row)\n",
    "        x_vars.append(age)\n",
    "        x_vars.append( getMonth(row))\n",
    "        x_vars.append( getjoinMonth(row))\n",
    "        x_vars.append(getCustSeniority(row))\n",
    "        income = getRent(row)\n",
    "        x_vars.append(income)\n",
    "        #x_vars.append(getMarriageIndex(row, age, sex, income) )\n",
    "        if row['fecha_dato'] == '2016-06-28':\n",
    "            prev_target_list = cust_dict.get(cust_id, [0]*22)\n",
    "            prod_tot = sum(prev_target_list[i] for i in prev_target_list if i == 1)\n",
    "            x_vars.append(prod_tot)\n",
    "            #lag6_target_list = lag6_cust_dict.get(cust_id, [0]*22)\n",
    "            lag5_target_list = lag5_cust_dict.get(cust_id, [0]*22)\n",
    "            lag4_target_list = lag4_cust_dict.get(cust_id, [0]*22)\n",
    "            lag3_target_list = lag3_cust_dict.get(cust_id, [0]*22)\n",
    "            lag2_target_list = lag2_cust_dict.get(cust_id, [0]*22)\n",
    "            lag1_target_list = lag1_cust_dict.get(cust_id, [0]*22)\n",
    "            lag_target_list = lag_cust_dict.get(cust_id, [0]*22)\n",
    "            x_vars_list.append(x_vars + prev_target_list + lag_target_list+ lag1_target_list+lag2_target_list+lag3_target_list+lag4_target_list+lag5_target_list)\n",
    "        elif row['fecha_dato'] == '2015-06-28':\n",
    "            prev_target_list = cust_dict.get(cust_id, [0]*22)\n",
    "            prod_tot = sum(prev_target_list[i] for i in prev_target_list if i == 1)\n",
    "            x_vars.append(prod_tot)\n",
    "            lag_target_list = lag_cust_dict.get(cust_id, [0]*22)\n",
    "            lag1_target_list = lag1_cust_dict.get(cust_id, [0]*22)\n",
    "            lag2_target_list = lag2_cust_dict.get(cust_id, [0]*22)\n",
    "            lag3_target_list = lag3_cust_dict.get(cust_id, [0]*22)\n",
    "            lag4_target_list = lag4_cust_dict.get(cust_id, [0]*22)\n",
    "            lag5_target_list = lag5_cust_dict.get(cust_id, [0]*22)\n",
    "            target_list = getTarget(row)\n",
    "            new_products = [max(x1 - x2,0) for (x1, x2) in zip(target_list, prev_target_list)]\n",
    "            if sum(new_products) > 0:\n",
    "                for ind, prod in enumerate(new_products):\n",
    "                    if prod>0:\n",
    "                        assert len(prev_target_list) == 22\n",
    "                        x_vars_list.append(x_vars+prev_target_list+lag_target_list+lag1_target_list+lag2_target_list+lag3_target_list+lag4_target_list+lag5_target_list)\n",
    "                        y_vars_list.append(ind)\n",
    "        \n",
    "        \n",
    "    return x_vars_list, y_vars_list, cust_dict, lag_cust_dict, lag1_cust_dict, lag2_cust_dict, lag3_cust_dict, lag4_cust_dict, lag5_cust_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def processData(in_file_name, cust_dict):\n",
    "    x_vars_list = []\n",
    "    y_vars_list = []\n",
    "    for row in csv.DictReader(in_file_name):\n",
    "        # use only the four months as specified by breakfastpirate #\n",
    "        if row['fecha_dato'] not in ['2015-05-28', '2015-06-28', '2016-05-28', '2016-06-28']:\n",
    "            continue  #tells the function to carry on if it encounters something outside these dates, stops an error being reported.\n",
    "\n",
    "        cust_id = int(row['ncodpers'])\n",
    "        if row['fecha_dato'] in ['2014-12-28', '2015-12-28']:\n",
    "            target_list = getTarget(row)\n",
    "            cust_dict[cust_id] =  target_list[:]\n",
    "            continue #returns a dictionary of {customer code: [products]}\n",
    "\n",
    "        x_vars = []\n",
    "        for col in cat_cols:\n",
    "            x_vars.append( getIndex(row, col) )\n",
    "        x_vars.append( getAge(row) )\n",
    "        x_vars.append( getCustSeniority(row) )\n",
    "        x_vars.append( getRent(row) ) #x_vars returns a list of normalised features.\n",
    "\n",
    "        if row['fecha_dato'] == '2016-06-28':\n",
    "            prev_target_list = cust_dict.get(cust_id, [0]*22) #returns a list of value from the key, defaults to all zero if key cannot be found\n",
    "            x_vars_list.append(x_vars + prev_target_list)    #x_vars_list returns a list of raw features(13), normalised features (3(age, seniority, renta)), and products for one customer, without cust_id\n",
    "        elif row['fecha_dato'] == '2015-06-28':\n",
    "            prev_target_list = cust_dict.get(cust_id, [0]*22)\n",
    "            target_list = getTarget(row)\n",
    "            new_products = [max(x1 - x2,0) for (x1, x2) in zip(target_list, prev_target_list)] \n",
    "            # zip: it makes tuples inside a list of the value of the product for 2016 and 2015. \n",
    "            # New_products takes only new products by comparing a list of products a year apart, and only takes the ones added in the most recent years, if they exist in both years then it means product was not added.  \n",
    "            if sum(new_products) > 0:\n",
    "                for ind, prod in enumerate(new_products): \n",
    "                    if prod>0:\n",
    "                        assert len(prev_target_list) == 22\n",
    "                        x_vars_list.append(x_vars+prev_target_list)\n",
    "                        y_vars_list.append(ind)\n",
    "            #y_vars_list returns a list of products added, by their position, ie: [0,2,5,8,7]\n",
    "            #enumerate returns a list of tuples with the first value being the position of the value in a list, second being the actual value (1 if product new, 0 if no product or product is not new).\n",
    "            # [(0,1), (1,0),(2,0),(3,1)] the first element being \"ind\" (0 is first product in the list, etc.), the second being \"prod\" 0 or 1, meaning if the product is new or not.\n",
    "    return x_vars_list, y_vars_list, cust_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def runXGB(train_X, train_y, seed_val=42):\n",
    "    param = {}\n",
    "    param['objective'] = 'multi:softprob' #Specify the learning task and the corresponding learning objective.\n",
    "    #multi:softprob is multiclass classification using the softProb objective, returns a matrix of class and probability for each customer.\n",
    "    param['eta'] = 0.05 #learning rate, lower rate gives better results but is computationaly more expensive. default = 0.3\n",
    "    param['max_depth'] = 9 #maximum depth of a tree, too high can lead to overfitting default=6\n",
    "    param['silent'] = 1 # 0:print running messages; 1: silent mode\n",
    "    param['num_class'] = 22 #number of classes to classify by, basically the number of targets\n",
    "    param['eval_metric'] = \"map@7\" # validation measure: multiclass negative log-likelihood\n",
    "    param['min_child_weight'] = 1 #minimum number of customers to split the tree further.\n",
    "    param['subsample'] = 0.85 #ratio of data used for subsample training.\n",
    "    param['colsample_bytree'] = 0.9 #ratio of columns to use for subsample\n",
    "    param['seed'] = seed_val #random number to ensure results are always the same\n",
    "    num_rounds = 50 #number of rounds for boosting\n",
    "\n",
    "    plst = list(param.items())\n",
    "    xgtrain = xgb.DMatrix(train_X, label=train_y)\n",
    "    model = xgb.train(plst, xgtrain, num_rounds)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting file processing\n",
      "Finished file processing\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21]\n",
      "((45679L, 173L), (45679L,))\n",
      "0:05:28.277000\n",
      "(929615L, 173L)\n",
      "0:06:08.657000\n",
      "Building model..\n",
      "Predicting..\n",
      "0:08:50.181000\n",
      "Getting the top products..\n",
      "0:08:55.149000\n",
      "Finished Model\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    start_time = datetime.datetime.now()\n",
    "    data_path = 'C:\\\\Users\\\\student12\\\\Desktop\\\\Santander\\\\' #defines the folder where the data is kept\n",
    "    train_file =  open(data_path + \"train_ver2.csv\")\n",
    "    print('Starting file processing')\n",
    "    #x_vars_list, y_vars_list, cust_dict = processData(train_file, {})\n",
    "    #x_vars_list, y_vars_list, cust_dict, lag_cust_dict = processDataMK(train_file, {}, {}) #loads the data set into a algorithm workable format\n",
    "    x_vars_list, y_vars_list, cust_dict, lag_cust_dict, lag1_cust_dict, lag2_cust_dict, lag3_cust_dict, lag4_cust_dict, lag5_cust_dict = processDataMK(train_file, {}, {}, {}, {}, {}, {}, {})\n",
    "    print('Finished file processing')\n",
    "    train_X = np.array(x_vars_list)\n",
    "    train_y = np.array(y_vars_list)\n",
    "    print(np.unique(train_y))\n",
    "    del x_vars_list, y_vars_list\n",
    "    train_file.close()\n",
    "    print(train_X.shape, train_y.shape)\n",
    "    print(datetime.datetime.now()-start_time)\n",
    "    test_file = open(data_path + \"test_ver2.csv\")\n",
    "    x_vars_list, y_vars_list, cust_dict, lag_cust_dict, lag1_cust_dict, lag2_cust_dict, lag3_cust_dict, lag4_cust_dict, lag5_cust_dict = processDataMK(test_file, cust_dict, lag_cust_dict, lag1_cust_dict, lag2_cust_dict, lag3_cust_dict, lag4_cust_dict, lag5_cust_dict)\n",
    "    #x_vars_list, y_vars_list, cust_dict, lag_cust_dict = processDataMK(test_file, cust_dict, lag_cust_dict)\n",
    "    #x_vars_list, y_vars_list, cust_dict = processData(test_file, cust_dict)\n",
    "    test_X = np.array(x_vars_list)\n",
    "    del x_vars_list\n",
    "    test_file.close()\n",
    "    print(test_X.shape)\n",
    "    print(datetime.datetime.now()-start_time)\n",
    "\n",
    "    print(\"Building model..\")\n",
    "    model = runXGB(train_X, train_y, seed_val=0)\n",
    "    del train_X, train_y\n",
    "    print(\"Predicting..\")\n",
    "    xgtest = xgb.DMatrix(test_X)\n",
    "    preds = model.predict(xgtest)\n",
    "    del test_X, xgtest\n",
    "    print(datetime.datetime.now()-start_time)\n",
    "\n",
    "    print(\"Getting the top products..\")\n",
    "    target_cols = np.array(target_cols)\n",
    "    preds = np.argsort(preds, axis=1)\n",
    "    preds = np.fliplr(preds)[:,:7]\n",
    "    test_id = np.array(pd.read_csv(data_path + \"test_ver2.csv\", usecols=['ncodpers'])['ncodpers'])\n",
    "    final_preds = [\" \".join(list(target_cols[pred])) for pred in preds]\n",
    "    out_df = pd.DataFrame({'ncodpers':test_id, 'added_products':final_preds})\n",
    "    out_df.to_csv('C:\\\\Users\\\\student12\\\\Desktop\\\\Santander\\\\xgb-0.5SubSample-try.csv', index=False)\n",
    "    print(datetime.datetime.now()-start_time)\n",
    "    print(\"Finished Model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
